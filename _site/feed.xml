<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Sahil&#39;s Blog</title>
    <description>A simple, beautiful theme for Jekyll that emphasizes content rather than aesthetic fluff.</description>
    <link>//</link>
    <atom:link href="//feed.xml" rel="self" type="application/rss+xml" />
    
      <item>
        <title>Hadoop and HDFS setup</title>
        <description>&lt;p&gt;Hadoop, formally called Apache Hadoop, is an Apache Software Foundation project and open source software platform for scalable, distributed computing.
Following are the installation steps:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;Check the ip of the server by running the command:&lt;/p&gt;

    &lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;
  $ ifconfig
 &lt;/code&gt;&lt;/p&gt;

    &lt;p&gt;Let’s say the ip looks somewhat like xxx.xxx.xx.xxx&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Check the hostname provided by Hetzner by running nslookup on the remote machine:&lt;/p&gt;

    &lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;
  $ nslookup xxx.xxx.xx.xxx
 &lt;/code&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;SSH to the server from your local machine:&lt;/p&gt;

    &lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;
  $ ssh root@xxx.xxx.xx.xxx
 &lt;/code&gt;&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;You should see something like the following after entering credentials:
	root@Ubuntu-1204-precise-64-minimal ~&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;Edit /etc/hostname :&lt;/p&gt;

    &lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;
   vim /etc/hostname
  &lt;/code&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Change all instances of the current  hostname (Ubuntu-1204-precise-64-minimal) to the Hostname provided by Hetzner and save the file.
  If everything goes well, you should see an entry in /etc/hosts like the one shown below.
  xxx.xxx.xx.xxx 	static.xxx.xxx.xx.xxx.clients.your-server.de&lt;/p&gt;

    &lt;p&gt;If you don’t see such an entry, add it manually.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Edit &lt;b&gt;/etc/hosts&lt;/b&gt; :&lt;/p&gt;

    &lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;
  $ vim /etc/hosts
 &lt;/code&gt;&lt;/p&gt;

    &lt;p&gt;(If its empty just enter machine name)&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Again change the hostname with $ vim /etc/hostname command&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Reboot the machine:&lt;/p&gt;

    &lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;
  $ sudo reboot
 &lt;/code&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Download the .tar.gz file of the latest JDK from &lt;b&gt;http://www.oracle.com/technetwork/java/javase/downloads/jdk7-downloads-1880260.htm
  lwget –no-cookies –header “Cookie: gpw_e24=http%3A%2F%2Fwww.oracle.com” “http://download.oracle.com/otn-pub/java/jdk/7u51-b13/jdk-7u51-linux-x64.tar.gz”&lt;/b&gt;&lt;/p&gt;

    &lt;p&gt;&lt;b&gt;UPDATE&lt;/b&gt; :&lt;/p&gt;

    &lt;p&gt;&lt;b&gt;NOTE-1&lt;/b&gt; : The version mentioned here is not the latest version of java. If you want to download the latest version, get the appropriate .tar.gz url. If you want the 7U51 version (used in the document) get the new link from archives page.&lt;/p&gt;

    &lt;p&gt;&lt;b&gt;NOTE-2&lt;/b&gt; : if the wget command used above doesn’t work, use &lt;b&gt;wget –no-check-certificate –no-cookies –header “Cookie:oraclelicense=accept-securebackup-cookie”&lt;/b&gt; instead of 
  &lt;b&gt;wget –no-cookies –header “Cookie: gpw_e24=http%3A%2F%2Fwww.oracle.com”&lt;/b&gt; on your local machine.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Create a folder for the java setup on the remote machine:&lt;/p&gt;

    &lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;
  $ mkdir /usr/local/java
  $ cd /usr/local/java
 &lt;/code&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Copy the java setup to remote machine by running the following command on your local machine :&lt;/p&gt;

    &lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;
  $ scp jdk-7u51-linux-x64.tar.gz root@148.xxx.xx.135:/usr/local/java/
 &lt;/code&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Run the following command (replace jdk-7u51 with the corresponding version name) on the remote machine:&lt;/p&gt;

    &lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;
  $ cd /usr/local/java
  $ sudo tar -xvzf jdk-7u51-linux-x64.tar.gz
 &lt;/code&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Check the name of the extracted folder (marked in bold, this may differ for you, and you need to use that particular name in the steps that follow):&lt;/p&gt;

    &lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;
  root@rq-namenode /usr/local/java  ls -a
      .  ..  jdk1.7.0_51  jdk-7u51-linux-x64.tar.gz
 &lt;/code&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;(Optional) At this point, you can remove the .tar.gz file&lt;/p&gt;

    &lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;
  rm jdk-7u51-linux-x64.tar.gz
 &lt;/code&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;$ &lt;b&gt;vim /etc/profile&lt;/b&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Add the following lines at the end of the file, and save the file (Esc :wq):&lt;/p&gt;

    &lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;
  JAVA_HOME=/usr/local/java/jdk1.7.0_51
  PATH=$PATH:$HOME/bin:$JAVA_HOME/bin
  export JAVA_HOME
  export PATH
 &lt;/code&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Inform the system where your Oracle Java JDK is located. This will tell the system that the new Oracle Java version is available for use.&lt;/p&gt;

    &lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;
  root@rq-namenode /usr/local/java  sudo update-alternatives --install &quot;/usr/bin/java&quot; &quot;java&quot; &quot;/usr/local/java/jdk1.7.0_79/bin/java&quot; 1
 &lt;/code&gt;&lt;/p&gt;

    &lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;
  root@rq-namenode /usr/local/java  sudo update-alternatives --install &quot;/usr/bin/javac&quot; &quot;javac&quot; &quot;/usr/local/java/jdk1.7.0_51/bin/javac&quot; 1
 &lt;/code&gt;&lt;/p&gt;

    &lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;
  root@rq-namenode /usr/local/java  sudo update-alternatives --install &quot;/usr/bin/javaws&quot; &quot;javaws&quot; &quot;/usr/local/java/jdk1.7.0_51/bin/javaws&quot; 1
 &lt;/code&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Inform the system that Oracle Java JDK must be the default Java.&lt;/p&gt;

    &lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;
  root@rq-namenode /usr/local/java  sudo update-alternatives --set java /usr/local/java/jdk1.7.0_79/bin/java
 &lt;/code&gt;&lt;/p&gt;

    &lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;
  root@rq-namenode /usr/local/java  sudo update-alternatives --set javac /usr/local/java/jdk1.7.0_51/bin/javac
 &lt;/code&gt;&lt;/p&gt;

    &lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;
  root@rq-namenode /usr/local/java  sudo update-alternatives --set javaws /usr/local/java/jdk1.7.0_51/bin/javaws
 &lt;/code&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Reload your system wide PATH &lt;b&gt;/etc/profile&lt;/b&gt; :&lt;/p&gt;

    &lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;
  root@rq-namenode /usr/local/java  . /etc/profile
 &lt;/code&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Check that java was installed correctly:&lt;/p&gt;

    &lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;
  root@rq-namenode ~  java -version
      java version &quot;1.7.0_51&quot;
      Java(TM) SE Runtime Environment (build 1.7.0_51-b13)
      Java HotSpot(TM) 64-Bit Server VM (build 24.51-b03, mixed mode)
 &lt;/code&gt;&lt;/p&gt;

    &lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;
  root@rq-namenode ~  javac -version
      javac 1.7.0_51
 &lt;/code&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Install NTP (if not already installed):&lt;/p&gt;

    &lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;
  root@rq-namenode ~  apt-get install ntp
 &lt;/code&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;b&gt;sudo /etc/init.d/ntp reload&lt;/b&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Disable SELinux:&lt;/p&gt;

    &lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;
   apt-get install selinux-utils
   getenforce
  &lt;/code&gt;&lt;/p&gt;

    &lt;p&gt;If result is disabled or permissive, no further action is required. Otherwise&lt;/p&gt;

    &lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;
   setenforce 0
  &lt;/code&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Disable IPTables:&lt;/p&gt;

    &lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;
   service ufw stop
  &lt;/code&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Install requirements:&lt;/p&gt;

    &lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;
   sudo apt-get install rpm
   sudo apt-get install curl
  &lt;/code&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Configure remote repositories and add gpg keys:&lt;/p&gt;

    &lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;
  wget http://public-repo-1.hortonworks.com/HDP/ubuntu12/2.x/hdp.list -O /etc/apt/sources.list.d/hdp.list
 &lt;/code&gt;&lt;/p&gt;

    &lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;
  wget http://public-repo-1.hortonworks.com/HDP/ubuntu12/2.0.6.1/hdp.list -O /etc/apt/sources.list.d/hdp.list
 &lt;/code&gt;&lt;/p&gt;

    &lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;
   gpg --keyserver pgp.mit.edu --recv-keys B9733A7A07513CAD
   gpg -a --export 07513CAD | apt-key add -
   apt-get update
  &lt;/code&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Download companion files&lt;/p&gt;

    &lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;
   mkdir /tmp/hadoop
   cd /tmp/hadoop
   wget http://public-repo-1.hortonworks.com/HDP/tools/2.1.5.0/hdp_manual_install_rpm_helper_files-2.1.5.695.tar.gz
   tar -zxvf hdp_manual_install_rpm_helper_files-2.0.6.101.tar.gz
   cd hdp_manual_install_rpm_helper_files-2.0.6.101/
  &lt;/code&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;b&gt;cd scripts&lt;/b&gt;&lt;/p&gt;

    &lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;
 vim usersAndGroups.sh
&lt;/code&gt;&lt;/p&gt;

    &lt;p&gt;Comment the variables (using ) corresponding to the services that are not being installed (from PIG_USER to OOZIE_USER) and save the file (Esc :wq)&lt;/p&gt;

    &lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;
 source usersAndGroups.sh
&lt;/code&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;b&gt;vim directories.sh&lt;/b&gt;&lt;/p&gt;

    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;  #Set the following variables and comment the rest:

  DFS_NAME_DIR=&quot;/grid/hadoop/hdfs/nn&quot;;

  DFS_DATA_DIR=&quot;/grid/hadoop/hdfs/dn&quot;;

  FS_CHECKPOINT_DIR=&quot;/grid/hadoop/hdfs/snn&quot;;

  HDFS_LOG_DIR=&quot;/var/log/hadoop/hdfs&quot;;

  HDFS_PID_DIR=&quot;/var/run/hadoop/hdfs&quot;;

  HADOOP_CONF_DIR=&quot;/etc/hadoop/conf&quot;;

  YARN_LOCAL_DIR=&quot;/grid/hadoop/yarn/local&quot;;

  YARN_LOG_DIR=&quot;/var/log/hadoop/yarn&quot;;

  YARN_LOCAL_LOG_DIR=&quot;/grid/hadoop/yarn/logs&quot;;

  YARN_PID_DIR=&quot;/var/run/hadoop/yarn&quot;;

  MAPRED_LOG_DIR=&quot;/var/log/hadoop/mapred&quot;;

  MAPRED_PID_DIR=&quot;/var/run/hadoop/mapred&quot;;

  ZOOKEEPER_DATA_DIR=&quot;/grid/hadoop/zookeeper/data&quot;;

  ZOOKEEPER_CONF_DIR=&quot;/etc/zookeeper/conf&quot;;

  ZOOKEEPER_LOG_DIR=&quot;/var/log/zookeeper&quot;;

  ZOOKEEPER_PID_DIR=&quot;/var/run/zookeeper&quot;;

  SQOOP_CONF_DIR=&quot;/etc/sqoop/conf&quot;;

  export HADOOP_LIBEXEC_DIR=/usr/lib/hadoop/libexec
&lt;/code&gt;&lt;/pre&gt;
    &lt;/div&gt;

    &lt;p&gt;Save the file and source it.&lt;/p&gt;

    &lt;p&gt;&lt;b&gt;source directories.sh&lt;/b&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;b&gt;vim ~/hadoopVariables.sh&lt;/b&gt;&lt;/p&gt;

    &lt;p&gt;#Add the following&lt;/p&gt;

    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; !/bin/sh

 #Hadoop Users and Groups
 #User which will own the HDFS services.
 HDFS_USER=hdfs ;

 #User which will own the YARN services.
 YARN_USER=yarn ;

 #User which will own the MapReduce services.
 MAPRED_USER=mapred ;

 #set owning the ZooKeeper services.
 ZOOKEEPER_USER=zookeeper ;

 #A common group shared by services.
 HADOOP_GROUP=hadoop ;

 #Hadoop Service - HDFS
 #Space separated list of directories where NameNode will store file system image. For example, /grid/hadoop/hdfs/nn /grid1/hadoop/hdfs/nn

 DFS_NAME_DIR=&quot;/grid/hadoop/hdfs/nn&quot;;

 #Space separated list of directories where DataNodes will store the blocks. For example, /grid/hadoop/hdfs/dn /grid1/hadoop/hdfs/dn /grid2/hadoop/hdfs/dn

 DFS_DATA_DIR=&quot;/grid/hadoop/hdfs/dn&quot;;

 #Space separated list of directories where SecondaryNameNode will store checkpoint image. For example, /grid/hadoop/hdfs/snn /grid1/hadoop/hdfs/snn /grid2/hadoop/hdfs/snn

 FS_CHECKPOINT_DIR=&quot;/grid/hadoop/hdfs/snn&quot;;

 #Directory to store the HDFS logs.
 HDFS_LOG_DIR=&quot;/var/log/hadoop/hdfs&quot;;

 #Directory to store the HDFS process ID.
 HDFS_PID_DIR=&quot;/var/run/hadoop/hdfs&quot;;

 #Directory to store the Hadoop configuration files.
 HADOOP_CONF_DIR=&quot;/etc/hadoop/conf&quot;;

 #Hadoop Service - YARN 
 #Space separated list of directories where YARN will store temporary data. For example, /grid/hadoop/yarn/local /grid1/hadoop/yarn/local /grid2/hadoop/yarn/local

 YARN_LOCAL_DIR=&quot;/grid/hadoop/yarn/local&quot;;

 #Directory to store the YARN logs.
 YARN_LOG_DIR=&quot;/var/log/hadoop/yarn&quot;; 

 #Space separated list of directories where YARN will store container log data. For example, /grid/hadoop/yarn/logs /grid1/hadoop/yarn/logs /grid2/hadoop/yarn/logs

 YARN_LOCAL_LOG_DIR=&quot;/grid/hadoop/yarn/logs&quot;;

 #Directory to store the YARN process ID.
 YARN_PID_DIR=&quot;/var/run/hadoop/yarn&quot;;

 #Hadoop Service - MAPREDUCE
 #Directory to store the MapReduce daemon logs.
 MAPRED_LOG_DIR=&quot;/var/log/hadoop/mapred&quot;;

 #Directory to store the mapreduce jobhistory process ID.
 MAPRED_PID_DIR=&quot;/var/run/hadoop/mapred&quot;;

 #Hadoop Service - ZOOKEEPER
 #Directory where ZooKeeper will store data
 ZOOKEEPER_DATA_DIR=&quot;/grid/hadoop/zookeeper/data&quot;;

 #Directory to store the ZooKeeper configuration files.
 ZOOKEEPER_CONF_DIR=&quot;/etc/zookeeper/conf&quot;;

 #Directory to store the ZooKeeper logs.
 ZOOKEEPER_LOG_DIR=&quot;/var/log/zookeeper&quot;;

 #Directory to store the ZooKeeper process ID.
 ZOOKEEPER_PID_DIR=&quot;/var/run/zookeeper&quot;;

 export HADOOP_LIBEXEC_DIR=/usr/lib/hadoop/libexec
&lt;/code&gt;&lt;/pre&gt;
    &lt;/div&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;b&gt;chmod +x hadoopVariables.sh&lt;/b&gt;&lt;/p&gt;

    &lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;
   source hadoopVariables.sh
  &lt;/code&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;
  python yarn-utils.py -c 6 -m 128 -d 1 -k False
 &lt;/code&gt;&lt;/p&gt;

    &lt;p&gt;Replace 6 by no.of cores, 128 by no. of gigabytes of RAM and 1 by no. of disks.Save the ouput for use in step 42 (yarn-site.xml)&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;b&gt;umask&lt;/b&gt;
  0022&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;
  sudo apt-get install openssh-server
 &lt;/code&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Install hadoop core services:&lt;/p&gt;

    &lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;
   sudo apt-get install hadoop hadoop-hdfs libhdfs0 libhdfs0-dev hadoop-yarn hadoop-mapreduce hadoop-client openssl
  &lt;/code&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Install compression libraries&lt;/p&gt;

    &lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;
  apt-get install libsnappy1 libsnappy-dev
 &lt;/code&gt;&lt;/p&gt;

    &lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;
  ln -sf /usr/lib64/libsnappy.so /usr/lib/hadoop/lib/native/.
 &lt;/code&gt;&lt;/p&gt;

    &lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;
  apt-get install liblzo2-2 liblzo2-dev hadoop-lzo
 &lt;/code&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Create the NameNode Directories (ONLY on NameNode):&lt;/p&gt;

    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;  mkdir -p $DFS_NAME_DIR;
  chown -R $HDFS_USER:$HADOOP_GROUP $DFS_NAME_DIR;
  chmod -R 755 $DFS_NAME_DIR;
&lt;/code&gt;&lt;/pre&gt;
    &lt;/div&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Create the Secondary NameNode Directories (ONLY on SecondaryNameNode):&lt;/p&gt;

    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;  mkdir -p $FS_CHECKPOINT_DIR;
  chown -R $HDFS_USER:$HADOOP_GROUP $FS_CHECKPOINT_DIR;
  chmod -R 755 $FS_CHECKPOINT_DIR;
&lt;/code&gt;&lt;/pre&gt;
    &lt;/div&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;ONLY on all the datanodes :&lt;/p&gt;

    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;  mkdir -p $DFS_DATA_DIR;
  chown -R $HDFS_USER:$HADOOP_GROUP $DFS_DATA_DIR;
  chmod -R 750 $DFS_DATA_DIR;
&lt;/code&gt;&lt;/pre&gt;
    &lt;/div&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Need to check about Zookeeper node:&lt;/p&gt;

    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;  mkdir -p $ZOOKEEPER_LOG_DIR;
  chown -R $ZOOKEEPER_USER:$HADOOP_GROUP $ZOOKEEPER_LOG_DIR;
  chmod -R 755 $ZOOKEEPER_LOG_DIR;
  mkdir -p $ZOOKEEPER_PID_DIR;
  chown -R $ZOOKEEPER_USER:$HADOOP_GROUP $ZOOKEEPER_PID_DIR;
  chmod -R 755 $ZOOKEEPER_PID_DIR;
  mkdir -p $ZOOKEEPER_DATA_DIR;
  chmod -R 755 $ZOOKEEPER_DATA_DIR;
  chown -R $ZOOKEEPER_USER:$HADOOP_GROUP $ZOOKEEPER_DATA_DIR;
&lt;/code&gt;&lt;/pre&gt;
    &lt;/div&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;ONLY on ResourceManager and all datanodes :&lt;/p&gt;

    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;  mkdir -p $YARN_LOCAL_DIR;
  chown -R $YARN_USER:$HADOOP_GROUP $YARN_LOCAL_DIR;
  chmod -R 755 $YARN_LOCAL_DIR;
  mkdir -p $YARN_LOCAL_LOG_DIR;
  chown -R $YARN_USER:$HADOOP_GROUP $YARN_LOCAL_LOG_DIR;
  chmod -R 755 $YARN_LOCAL_LOG_DIR;
&lt;/code&gt;&lt;/pre&gt;
    &lt;/div&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;On all nodes:&lt;/p&gt;

    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;  mkdir -p $HDFS_LOG_DIR;
  chown -R $HDFS_USER:$HADOOP_GROUP $HDFS_LOG_DIR;
  chmod -R 755 $HDFS_LOG_DIR;
  mkdir -p $YARN_LOG_DIR;
  chown -R $YARN_USER:$HADOOP_GROUP $YARN_LOG_DIR;
  chmod -R 755 $YARN_LOG_DIR;
  mkdir -p $HDFS_PID_DIR;
  chown -R $HDFS_USER:$HADOOP_GROUP $HDFS_PID_DIR;
  chmod -R 755 $HDFS_PID_DIR;
  mkdir -p $YARN_PID_DIR;
  chown -R $YARN_USER:$HADOOP_GROUP $YARN_PID_DIR;
  chmod -R 755 $YARN_PID_DIR;
  mkdir -p $MAPRED_LOG_DIR;
  chown -R $MAPRED_USER:$HADOOP_GROUP $MAPRED_LOG_DIR;
  chmod -R 755 $MAPRED_LOG_DIR;
  mkdir -p $MAPRED_PID_DIR;
  chown -R $MAPRED_USER:$HADOOP_GROUP $MAPRED_PID_DIR;
  chmod -R 755 $MAPRED_PID_DIR;
&lt;/code&gt;&lt;/pre&gt;
    &lt;/div&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;b&gt;cd /tmp/hadoop/hdp_manual_install_rpm_helper_files-2.0.6.101/configuration_files/core_hadoop&lt;/b&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;b&gt;vim core-site.xml&lt;/b&gt;&lt;/p&gt;

    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;  &amp;lt;!--Make the following change--&amp;gt;
 	&amp;lt;property&amp;gt;
  	&amp;lt;name&amp;gt;fs.defaultFS&amp;lt;/name&amp;gt;
 	&amp;lt;value&amp;gt;hdfs://static.xxx.xxx.xx.xxx.clients.your-server.de:8020&amp;lt;/value&amp;gt;
 	&amp;lt;/property&amp;gt;
&lt;/code&gt;&lt;/pre&gt;
    &lt;/div&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;b&gt;vim hdfs-site.xml&lt;/b&gt;&lt;/p&gt;

    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;  &amp;lt;!--Make the following changes--&amp;gt;
  &amp;lt;property&amp;gt;
  	&amp;lt;name&amp;gt;dfs.datanode.data.dir&amp;lt;/name&amp;gt;
  	&amp;lt;value&amp;gt;file:///grid/hadoop/hdfs/dn&amp;lt;/value&amp;gt;
  &amp;lt;/property&amp;gt;
  &amp;lt;property&amp;gt;
 	&amp;lt;name&amp;gt;dfs.namenode.http-address&amp;lt;/name&amp;gt;
  	&amp;lt;value&amp;gt;static.xxx.xxx.xx.xxx.clients.your-server.de:50070&amp;lt;/value&amp;gt;
  &amp;lt;/property&amp;gt;
  &amp;lt;property&amp;gt;
  	&amp;lt;name&amp;gt;dfs.namenode.name.dir&amp;lt;/name&amp;gt;
  	&amp;lt;value&amp;gt;file:///grid/hadoop/hdfs/nn&amp;lt;/value&amp;gt;
  &amp;lt;/property&amp;gt;
  &amp;lt;property&amp;gt;
  	&amp;lt;name&amp;gt;dfs.namenode.checkpoint.dir&amp;lt;/name&amp;gt;
  	&amp;lt;value&amp;gt;/grid/hadoop/hdfs/snn&amp;lt;/value&amp;gt;
  	&amp;lt;/property&amp;gt;
  &amp;lt;property&amp;gt;
  	&amp;lt;name&amp;gt;dfs.namenode.secondary.http-address&amp;lt;/name&amp;gt;
  	&amp;lt;value&amp;gt;static.xxx.xxx.xx.xxx.clients.your-server.de:50090&amp;lt;/value&amp;gt;
  &amp;lt;/property&amp;gt;
&lt;/code&gt;&lt;/pre&gt;
    &lt;/div&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;b&gt;vim yarn-site.xml&lt;/b&gt;&lt;/p&gt;

    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;  &amp;lt;!--Make the following changes--&amp;gt;
  	&amp;lt;property&amp;gt;
  		&amp;lt;name&amp;gt;yarn.nodemanager.local-dirs&amp;lt;/name&amp;gt;
  		&amp;lt;value&amp;gt;/grid/hadoop/yarn/local&amp;lt;/value&amp;gt;
	&amp;lt;/property&amp;gt;
  	&amp;lt;property&amp;gt;
  		&amp;lt;name&amp;gt;yarn.log.server.url&amp;lt;/name&amp;gt;
  		&amp;lt;value&amp;gt;http://static.xxx.xxx.xx.xxx.clients.your-server.de:19888/jobhistory/logs&amp;lt;/value&amp;gt;
	&amp;lt;/property&amp;gt;
  	&amp;lt;property&amp;gt;
  		&amp;lt;name&amp;gt;yarn.resourcemanager.admin.address&amp;lt;/name&amp;gt;
  		&amp;lt;value&amp;gt;static.xxx.xxx.xx.xxx.clients.your-server.de:8141&amp;lt;/value&amp;gt;
	&amp;lt;/property&amp;gt;
  	&amp;lt;property&amp;gt;
  		&amp;lt;name&amp;gt;yarn.scheduler.maximum-allocation-mb&amp;lt;/name&amp;gt;
  		&amp;lt;value&amp;gt;105984&amp;lt;/value&amp;gt;
	&amp;lt;/property&amp;gt;
  	&amp;lt;property&amp;gt;
  		&amp;lt;name&amp;gt;yarn.nodemanager.resource.memory-mb&amp;lt;/name&amp;gt;
  		&amp;lt;value&amp;gt;105984&amp;lt;/value&amp;gt;
	&amp;lt;/property&amp;gt;
  	&amp;lt;property&amp;gt;
  		&amp;lt;name&amp;gt;yarn.nodemanager.log-dirs&amp;lt;/name&amp;gt;
  		&amp;lt;value&amp;gt;/grid/hadoop/yarn/logs&amp;lt;/value&amp;gt;
	&amp;lt;/property&amp;gt;
  	&amp;lt;property&amp;gt;
  		&amp;lt;name&amp;gt;yarn.resourcemanager.scheduler.class&amp;lt;/name&amp;gt;
  		&amp;lt;value&amp;gt;org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler&amp;lt;/value&amp;gt;
	&amp;lt;/property&amp;gt;
  	&amp;lt;property&amp;gt;
  		&amp;lt;name&amp;gt;yarn.resourcemanager.resource-tracker.address&amp;lt;/name&amp;gt;
  		&amp;lt;value&amp;gt;static.xxx.xxx.xx.xxx.clients.your-server.de:8025&amp;lt;/value&amp;gt;
	&amp;lt;/property&amp;gt;
  	&amp;lt;property&amp;gt;
  		&amp;lt;name&amp;gt;yarn.scheduler.minimum-allocation-mb&amp;lt;/name&amp;gt;
  		&amp;lt;value&amp;gt;35328&amp;lt;/value&amp;gt;
	&amp;lt;/property&amp;gt;
  	&amp;lt;property&amp;gt;
  		&amp;lt;name&amp;gt;yarn.resourcemanager.webapp.address&amp;lt;/name&amp;gt;
  		&amp;lt;value&amp;gt;static.xxx.xxx.xx.xxx.clients.your-server.de:8088&amp;lt;/value&amp;gt;
	&amp;lt;/property&amp;gt;
  	&amp;lt;property&amp;gt;
  		&amp;lt;name&amp;gt;yarn.resourcemanager.address&amp;lt;/name&amp;gt;
  		&amp;lt;value&amp;gt;static.xxx.xxx.xx.xxx.clients.your-server.de:8050&amp;lt;/value&amp;gt;
	&amp;lt;/property&amp;gt;
  	&amp;lt;property&amp;gt;
  		&amp;lt;name&amp;gt;yarn.resourcemanager.scheduler.address&amp;lt;/name&amp;gt;
  		&amp;lt;value&amp;gt;static.xxx.xxx.xx.xxx.clients.your-server.de:8030&amp;lt;/value&amp;gt;
	&amp;lt;/property&amp;gt;
&lt;/code&gt;&lt;/pre&gt;
    &lt;/div&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;b&gt;vim mapred-site.xml&lt;/b&gt;&lt;/p&gt;

    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;  &amp;lt;!--Make the following changes--&amp;gt;
  	&amp;lt;property&amp;gt;
  		&amp;lt;name&amp;gt;mapreduce.jobhistory.address&amp;lt;/name&amp;gt;
  		&amp;lt;value&amp;gt;static.xxx.xx.xxx.xxx.clients.your-server.de:10020&amp;lt;/value&amp;gt;
	&amp;lt;/property&amp;gt;
  	&amp;lt;property&amp;gt;
  		&amp;lt;name&amp;gt;mapreduce.cluster.reduce.memory.mb&amp;lt;/name&amp;gt;
  		&amp;lt;value&amp;gt;35328&amp;lt;/value&amp;gt;
	&amp;lt;/property&amp;gt;
  	&amp;lt;property&amp;gt;
  		&amp;lt;name&amp;gt;mapred.child.java.opts&amp;lt;/name&amp;gt;
  		&amp;lt;value&amp;gt;-Xmx28262m&amp;lt;/value&amp;gt;
	&amp;lt;/property&amp;gt;
  	&amp;lt;property&amp;gt;
  		&amp;lt;name&amp;gt;mapred.cluster.max.reduce.memory.mb&amp;lt;/name&amp;gt;
  		&amp;lt;value&amp;gt;35328&amp;lt;/value&amp;gt;
	&amp;lt;/property&amp;gt;
  	&amp;lt;property&amp;gt;
  		&amp;lt;name&amp;gt;mapred.cluster.max.map.memory.mb&amp;lt;/name&amp;gt;
  		&amp;lt;value&amp;gt;35328&amp;lt;/value&amp;gt;
	&amp;lt;/property&amp;gt;
  	&amp;lt;property&amp;gt;
  		&amp;lt;name&amp;gt;mapreduce.jobhistory.webapp.address&amp;lt;/name&amp;gt;
  		&amp;lt;value&amp;gt;static.xxx.xx.xxx.xxx.clients.your-server.de:19888&amp;lt;/value&amp;gt;
	&amp;lt;/property&amp;gt;
  	&amp;lt;property&amp;gt;
  		&amp;lt;name&amp;gt;mapreduce.map.memory.mb&amp;lt;/name&amp;gt;
  		&amp;lt;value&amp;gt;35328&amp;lt;/value&amp;gt;
	&amp;lt;/property&amp;gt;
  	&amp;lt;property&amp;gt;
  		&amp;lt;name&amp;gt;mapreduce.task.io.sort.mb&amp;lt;/name&amp;gt; 
  		&amp;lt;!--Please keep this as 1024 --&amp;gt;
  		&amp;lt;value&amp;gt;1024&amp;lt;/value&amp;gt;
	&amp;lt;/property&amp;gt;
  	&amp;lt;property&amp;gt;
  		&amp;lt;name&amp;gt;mapred.cluster.map.memory.mb&amp;lt;/name&amp;gt;
  		&amp;lt;value&amp;gt;35328&amp;lt;/value&amp;gt;
	&amp;lt;/property&amp;gt;
  	&amp;lt;property&amp;gt;
  		&amp;lt;name&amp;gt;mapreduce.reduce.memory.mb&amp;lt;/name&amp;gt;
  		&amp;lt;value&amp;gt;35328&amp;lt;/value&amp;gt;
	&amp;lt;/property&amp;gt;
&lt;/code&gt;&lt;/pre&gt;
    &lt;/div&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Copy the configuration files to &lt;b&gt;/etc/hadoop/conf/&lt;/b&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;b&gt;vim /etc/hadoop/conf/hadoop-env.sh&lt;/b&gt;&lt;/p&gt;

    &lt;p&gt;Comment the line containing export JAVA_HOME&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;b&gt;vim /etc/rc.local&lt;/b&gt;&lt;/p&gt;

    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;  Add the following lines (after the first block of comments):
  mkdir /var/run/hadoop
  chown -R hdfs:hadoop /var/run/hadoop
  chmod -R 755 /var/run/hadoop

  mkdir /var/run/hadoop-yarn
  chown -R yarn:hadoop /var/run/hadoop-yarn
  chmod -R 755 /var/run/hadoop-yarn

  mkdir /var/run/hadoop-mapreduce
  chown -R mapred:hadoop /var/run/hadoop-mapreduce
  chmod -R 755 /var/run/hadoop-mapreduce

  mkdir /var/run/hbase
  chown -R hbase:hadoop /var/run/hbase
  chmod -R 755 /var/run/hbase
&lt;/code&gt;&lt;/pre&gt;
    &lt;/div&gt;

    &lt;p&gt;(Need to use distributed cache) Copy all the lib jars from &lt;b&gt;/home/rq/rocq/sparq_backend/lib&lt;/b&gt; to &lt;b&gt;/usr/lib/hadoop-mapreduce/&lt;/b&gt;
  ** add &lt;b&gt;/usr/lib/rocq&lt;/b&gt; folder &amp;amp; &lt;b&gt;/usr/lib/hadoop-mapreduce/&lt;/b&gt; folder jars while adding new datanodes or any other node to the cluster&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;ONLY on the namenode, format and start the namenode&lt;/p&gt;

    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;su $HDFS_USER
hdfs namenode -format
&lt;/code&gt;&lt;/pre&gt;
    &lt;/div&gt;

    &lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;
   /usr/lib/hadoop/sbin/hadoop-daemon.sh --config /etc/hadoop/conf start namenode
 &lt;/code&gt;&lt;/p&gt;

    &lt;p&gt;If the above commands execute properly, then the namenode setup is working.
  When namenode is running, see : http://static.136.xx.xxx.148.clients.your-server.de:50070/&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Execute these commands on the SecondaryNameNode:&lt;/p&gt;

    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;su $HDFS_USER
&lt;/code&gt;&lt;/pre&gt;
    &lt;/div&gt;

    &lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;
   /usr/lib/hadoop/sbin/hadoop-daemon.sh --config /etc/hadoop/conf start secondarynamenode
  &lt;/code&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Execute these commands on all DataNodes:&lt;/p&gt;

    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;su $HDFS_USER
&lt;/code&gt;&lt;/pre&gt;
    &lt;/div&gt;

    &lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;
   /usr/lib/hadoop/sbin/hadoop-daemon.sh --config /etc/hadoop/conf start datanode
  &lt;/code&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Create hdfs user directory in HDFS:&lt;/p&gt;

    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;su $HDFS_USER
hadoop fs -mkdir -p /user/hdfs
&lt;/code&gt;&lt;/pre&gt;
    &lt;/div&gt;

    &lt;p&gt;Try copying a file into HDFS and listing that file:&lt;/p&gt;

    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;su $HDFS_USER
hadoop fs -copyFromLocal /etc/passwd passwd
hadoop fs -ls 
&lt;/code&gt;&lt;/pre&gt;
    &lt;/div&gt;

    &lt;p&gt;If  you see the file listed, then it has been created properly.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Start YARN
  Execute these commands from the ResourceManager server:&lt;/p&gt;

    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;su $YARN_USER
export HADOOP_LIBEXEC_DIR=/usr/lib/hadoop/libexec
&lt;/code&gt;&lt;/pre&gt;
    &lt;/div&gt;

    &lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;
  /usr/lib/hadoop-yarn/sbin/yarn-daemon.sh --config /etc/hadoop/conf start resourcemanager
 &lt;/code&gt;&lt;/p&gt;

    &lt;p&gt;Execute these commands from all NodeManager nodes:&lt;/p&gt;

    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;su $YARN_USER
export HADOOP_LIBEXEC_DIR=/usr/lib/hadoop/libexec
&lt;/code&gt;&lt;/pre&gt;
    &lt;/div&gt;

    &lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;
   /usr/lib/hadoop-yarn/sbin/yarn-daemon.sh --config /etc/hadoop/conf start nodemanager
  &lt;/code&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Start MapReduce JobHistory Server (on the namenode):
  We need to do this step on data-nodes before starting node manager, else it shows error on health check and shows unhealthy nodes.&lt;/p&gt;

    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;chown -R root:hadoop /usr/lib/hadoop-yarn/bin/container-executor
chmod -R 6050 /usr/lib/hadoop-yarn/bin/container-executor
	
$ su hdfs
$ hadoop fs -mkdir -p /mr-history/tmp
$ hadoop fs -chmod -R 1777 /mr-history/tmp
$ hadoop fs -mkdir -p /mr-history/done
$ hadoop fs -chmod -R 1777 /mr-history/done
$ hadoop fs -chown -R mapred:hdfs /mr-history
$ hadoop fs -mkdir -p /app-logs
$ hadoop fs -chmod -R 1777 /app-logs 
$ hadoop fs -chown yarn /app-logs
$ exit


$ su mapred
$ export HADOOP_LIBEXEC_DIR=/usr/lib/hadoop/libexec/ 
$ /usr/lib/hadoop-mapreduce/sbin/mr-jobhistory-daemon.sh --config /etc/hadoop/conf start historyserver
&lt;/code&gt;&lt;/pre&gt;
    &lt;/div&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Browse the Recource Manager :&lt;/p&gt;

    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;http://static.136.xx.xxx.148.clients.your-server.de:8088/
&lt;/code&gt;&lt;/pre&gt;
    &lt;/div&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Start a sample MapReduce Job:&lt;/p&gt;

    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;su hdfs
$ /usr/lib/hadoop/bin/hadoop jar /usr/lib/hadoop-mapreduce/hadoop-mapreduce-examples-2.2.0.2.0.6.0-101.jar teragen 10000 /tmp/teragenout 
$ /usr/lib/hadoop/bin/hadoop jar /usr/lib/hadoop-mapreduce/hadoop-mapreduce-examples-2.2.0.2.0.6.0-76.jar terasort /tmp/teragenout /tmp/terasortout
&lt;/code&gt;&lt;/pre&gt;
    &lt;/div&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;If there are no errors, then the setup is working!&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;For stopping follow this order&lt;/p&gt;

    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;Job History Server
NodeManager
ResourceManager
DataNodes
SecondaryNameNode
NameNode
&lt;/code&gt;&lt;/pre&gt;
    &lt;/div&gt;
  &lt;/li&gt;
&lt;/ul&gt;
</description>
        <pubDate>Sat, 09 Jul 2016 16:51:29 +0530</pubDate>
        <link>//hadoop/hdfs/2016/07/09/hadoop_setup/</link>
        <guid isPermaLink="true">//hadoop/hdfs/2016/07/09/hadoop_setup/</guid>
      </item>
    
  </channel>
</rss>
